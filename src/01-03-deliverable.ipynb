{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04f91fdf",
   "metadata": {},
   "source": [
    "# Explore Graph using Neo4j\n",
    "\n",
    "In this section we will explore the graph we just created using Cypher and the Graph Data Science (GDS) library for Neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5285ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import py2neo\n",
    "import umap\n",
    "\n",
    "from py2neo import Graph\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16314eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../../data/project-1\"\n",
    "\n",
    "NEO4J_DUMP = os.path.join(DATA_DIR, \"neo4j-dump.json\")\n",
    "NEO4J_LABELS = os.path.join(DATA_DIR, \"neo4j-labels.tsv\")\n",
    "\n",
    "NODE_VEC_FILE = os.path.join(DATA_DIR, \"stat-abstract-vectors.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d00b57f",
   "metadata": {},
   "source": [
    "## Connect to Neo4j server\n",
    "\n",
    "The code below connects to the Neo4j server using the `bolt` interface.\n",
    "\n",
    "For a sanity check, enter a Cypher query to count the number of nodes of type `Article` in the graph. You should see 50427 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bec228",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"admin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd703e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samity check\n",
    "result = graph.run(\n",
    "    ## your code here\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    ## end your code here\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3a4cf3",
   "metadata": {},
   "source": [
    "## Create subgraph for GDS algorithms\n",
    "\n",
    "GDS needs a subgraph to run, even if we are running the algorithm on the entire graph. So we create a virtual subgraph as shown below, with the `Article` node type and `SIMILAR_TO` relationship type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd8f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.run(\"\"\"\n",
    "CALL gds.graph.create('av-graph-gds', 'Article', 'SIMILAR_TO')\n",
    "\"\"\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d004800",
   "metadata": {},
   "source": [
    "## Important Nodes\n",
    "\n",
    "### Degree Centrality\n",
    "\n",
    "A measure of importance of a node in a graph is the number of neighbors it is connected to. Look up the [documentation for the GDS Degree Centrality](https://neo4j.com/docs/graph-data-science/current/algorithms/degree-centrality/) to learn more about this measure and provide the Cypher query in the code block below to generate the degree centrality for nodes in the subgraph, and return the top 10 nodes with the highest degree centrality. Include the `doc_id`, `title`, `category`, and the centrality `score` in your output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e789140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result_as_dataframe(result, colnames, filterset=None):\n",
    "    result_lod = []\n",
    "    already_seen_docids = set()\n",
    "    for row in result:\n",
    "        doc_id, title, category, page_rank = row\n",
    "        if filterset is not None and doc_id in filterset:\n",
    "            continue\n",
    "        if doc_id in already_seen_docids:\n",
    "            continue\n",
    "        result_dict = {}\n",
    "        for i, colname in enumerate(colnames):\n",
    "            result_dict[colname] = row[i]\n",
    "        result_lod.append(result_dict)\n",
    "        already_seen_docids.add(doc_id)\n",
    "    result_df = pd.DataFrame(result_lod)\n",
    "    return result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2567385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.run(\n",
    "    # your code here\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    # end your code here\n",
    ")\n",
    "show_result_as_dataframe(result, [\"doc_id\", \"title\", \"category\", \"score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a6f14f",
   "metadata": {},
   "source": [
    "### PageRank\n",
    "\n",
    "Another useful measure of central tendency (and hence importance) is the PageRank algorithm. It is more involved than Degree Centrality, and takes into account not only the number of neighbors a node has, but also how important they are. The importance of neighbor nodes is, in turn, dependent on the importance of their neighbors. Read about PageRank in the [GDS Documentation page for PageRank](https://neo4j.com/docs/graph-data-science/current/algorithms/page-rank/), then fill out the Cypher code snippet to compute the PageRank and return the top 10 articles by Page Rank (higher is better). \n",
    "\n",
    "Set the configuration options as `{ maxIterations: 20, dampingFactor: 0.85 }`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63fc6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.run(\n",
    "    # your code here\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    # end your code here\n",
    ")\n",
    "show_result_as_dataframe(result, [\"doc_id\", \"title\", \"category\", \"score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51715b4",
   "metadata": {},
   "source": [
    "### Between-ness Centrality\n",
    "\n",
    "A slightly different measure of centrality is Between-ness Centrality. It identifies nodes that are placed as bridges between two relatively dense clusters. In practice they represent articles that bridge or cross thematic boundaries. They are expensive to compute for dense graphs since they involve computing paths between all pairs of nodes. In order to reduce the computation, we will configure the call to the between-ness centrality algorithm to only look at around 1000 nodes. Check out the [GDS Documentation for Betweenness Centrality](https://neo4j.com/docs/graph-data-science/current/algorithms/betweenness-centrality/) and fill in the Cypher query to find the nodes with the top 10 highest values for between-ness centrality.\n",
    "\n",
    "Configure a `samplingSize` of 1000 nodes.\n",
    "\n",
    "**NOTE: Expect this call to take some time to complete, even with `samplingSize` set to 1000.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8922ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.run(\n",
    "    # your code here\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    ## end of your code here\n",
    ")\n",
    "show_result_as_dataframe(result, [\"doc_id\", \"title\", \"category\", \"score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1156667",
   "metadata": {},
   "source": [
    "## Community Detection\n",
    "\n",
    "### Louvain Modularity\n",
    "\n",
    "Louvain is a popular community detection algorithm. It works by maximizing the modularity of the created cluster, where the modularity quantifies the quality of assignment of nodes to communities compared to a random graph.\n",
    "\n",
    "For our community detection algorithms, we will adopt a two step procedure. First we will call the algorithm to write the generated community as a node property, then we will count the number of nodes in each community.\n",
    "\n",
    "To guide the community creation process, we will use the `category` as a seed property. Because Louvain algorithm needs an integer seed category, we will be writing out a derived field `cat_id` as shown below. \n",
    "\n",
    "Once we have our derived property `cat_id` we can use it as the seed property for the GDS Louvain algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66aa357",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat2id = {\n",
    "    \"stat.AP\": 0,\n",
    "    \"stat.CO\": 1,\n",
    "    \"stat.ME\": 2,\n",
    "    \"stat.ML\": 3,\n",
    "    \"stat.OT\": 4, \n",
    "    \"stat.TH\": 5\n",
    "}\n",
    "for category, cat_id in cat2id.items():\n",
    "    cypher_query = \"\"\"MATCH (n {category: \"%s\"}) SET n.cat_id = %d\"\"\" % (category, cat_id)\n",
    "    print(cypher_query)\n",
    "    graph.run(cypher_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2a2840",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.run(\"\"\"\n",
    "CALL gds.graph.create('av-graph-gds-1','Article','SIMILAR_TO', \n",
    "    {\n",
    "        nodeProperties: { catId: 'cat_id' }\n",
    "    })\n",
    "\"\"\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d24954c",
   "metadata": {},
   "source": [
    "Now read about the [Louvain Community Detection Algorithm in GDS](https://neo4j.com/docs/graph-data-science/current/algorithms/louvain/), and complete the code below to write out the commmunity predicted by the Louvain algorithm into the node property `community_lv`.\n",
    "\n",
    "Remember to set the `seedProperty` in the configuration as discussed above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2b0085",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.run(\n",
    "    # your code here\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    # end of your code here\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f803494",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_communities = result.data()[0][\"communityCount\"]\n",
    "num_communities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c673b4d4",
   "metadata": {},
   "source": [
    "One way to find the number of nodes in each community is through the Cypher query:\n",
    "\n",
    "```\n",
    "MATCH (a:Article)\n",
    "RETURN a.community_lp, COUNT(a) AS num_articles\n",
    "```\n",
    "\n",
    "But this returns only the top 3 counts. The code below loops through the different community IDs and for each value of `community_lv` it will report the counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b61669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def article_count_by_community(graph, comm_field_name, num_communities):\n",
    "    community_counts = []\n",
    "    for i in range(num_communities):\n",
    "        result_row = graph.run(\n",
    "            \"\"\"\n",
    "                MATCH (a:Article {%s: %d})\n",
    "                RETURN a.%s, COUNT(a) AS num_articles\n",
    "            \"\"\" % (comm_field_name, i, comm_field_name)\n",
    "        )\n",
    "        num_articles = result_row.data()[0][\"num_articles\"]\n",
    "        community_counts.append((i, num_articles))\n",
    "    return community_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d299d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(article_count_by_community(graph, \"community_lv\", num_communities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0440cc1f",
   "metadata": {},
   "source": [
    "### Label Propagation\n",
    "\n",
    "Label Propagation is another community detection algorithm that works by propagating labels across the network. You can read about [Label Propagation in the GDS Documentation](https://neo4j.com/docs/graph-data-science/current/algorithms/label-propagation/).\n",
    "\n",
    "We will follow a similar strategy to run the Label Propagation algorithm on our graph as we did with the Louvain algorithm. Here we will write the community ID predicted by the Label Propagation algorithm into the `community_lp` node property. As with Louvain, we will see our Label Propagation algorithm with the `category` as the `seedProperty`.\n",
    "\n",
    "Once the algorithm has finished running, we will look at the counts of nodes in each community.\n",
    "\n",
    "Complete the code blocks below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b497dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.run(\n",
    "    ## your code here\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    ## end your code here\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0f09cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_communities = result.data()[0][\"communityCount\"]\n",
    "num_communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7f6028",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(article_count_by_community(graph, \"community_lp\", num_communities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b050cf",
   "metadata": {},
   "source": [
    "### Visualizing Communities\n",
    "\n",
    "We will visualize the communities that was implicitly known via the `category` property against the communities predicted by the Louvain and Label Propagation algorithms respectively.\n",
    "\n",
    "To do that, we will need to export the data from Numpy and convert the data into Numpy matrices. To export the data, we can run the following Cypher query.\n",
    "\n",
    "Note that you will also need to install UMAP by running the following command:\n",
    "\n",
    "```\n",
    "pip install umap-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab85907",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.run(\"\"\"CALL apoc.export.json.all(\"/tmp/neo4j-dump.json\")\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9d0ad0",
   "metadata": {},
   "source": [
    "The dump contains all nodes and relationships in JSON-L format, one line per node and one line per relationship. We reformat this to extract just a TSV file with `doc_id` of the article, the implicit `category` label, and the predicted `community_lv` and `community_lp` values from Louvain and Label Propagation algorithms respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692c4be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 0\n",
    "flab = open(NEO4J_LABELS, \"w\")\n",
    "with open(\"/tmp/neo4j-dump.json\", \"r\") as fdump:\n",
    "    for line in fdump:\n",
    "        data = json.loads(line.strip())\n",
    "        if data[\"type\"] == \"node\" and data[\"labels\"][0] == \"Article\":\n",
    "            doc_id = data[\"properties\"][\"doc_id\"]\n",
    "            category = data[\"properties\"][\"category\"]\n",
    "            community_lv = data[\"properties\"][\"community\"]\n",
    "            community_lp = data[\"properties\"][\"community_lp\"]\n",
    "            flab.write(\"{:s}\\t{:s}\\t{:d}\\t{:d}\\n\".format(doc_id, category, community_lv, community_lp))\n",
    "            if num_nodes % 10000 == 0:\n",
    "                print(\"{:d} node labels written\".format(num_nodes))\n",
    "            num_nodes += 1\n",
    "\n",
    "print(\"{:d} node labels written, COMPLETE\".format(num_nodes))\n",
    "flab.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c19dc69",
   "metadata": {},
   "source": [
    "### Extract labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8d7174",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat, y_lv, y_lp = [], [], []\n",
    "num_read = 0\n",
    "with open(NEO4J_LABELS, \"r\") as flab:\n",
    "    for line in flab:\n",
    "        if num_read % 10000 == 0:\n",
    "            print(\"{:d} labels read\".format(num_read))\n",
    "        docid, label_c, label_lv, label_lp = line.strip().split('\\t')\n",
    "        y_cat.append(label_c)\n",
    "        y_lv.append(int(label_lv))\n",
    "        y_lp.append(int(label_lp))\n",
    "        num_read += 1\n",
    "        \n",
    "print(\"{:d} labels read, COMPLETE\".format(num_read))\n",
    "len(y_cat), len(y_lv), len(y_lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901b83be",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cats = [cat for cat in list(set(y_cat))]\n",
    "cid_to_cat = {i:c for i, c in enumerate(unique_cats)}\n",
    "cat_to_cid = {v:k for k, v in cid_to_cat.items()}\n",
    "cat_to_cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daad8dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_c = np.array([cat_to_cid[y] for y in y_cat])\n",
    "y_c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b81b9af",
   "metadata": {},
   "source": [
    "### Extract Node vectors and project to 2-D\n",
    "\n",
    "Read the [UMAP Documentation page](https://umap-learn.readthedocs.io/en/latest/) and complete the code to project the matrix X of node vectors from 300 dimensions down to 2 using UMAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5596138",
   "metadata": {},
   "outputs": [],
   "source": [
    "docid_to_idx = {}\n",
    "vecs = []\n",
    "num_read = 0\n",
    "with open(NODE_VEC_FILE, \"r\") as fvec:\n",
    "    for i, line in enumerate(fvec):\n",
    "        if num_read % 10000 == 0:\n",
    "            print(\"{:d} articles read\".format(num_read))\n",
    "        docid, vec_str = line.strip().split('\\t')\n",
    "        vec = [float(x) for x in vec_str.split(',')]\n",
    "        vecs.append(vec)\n",
    "        docid_to_idx[docid] = i\n",
    "        num_read += 1\n",
    "\n",
    "print(\"{:d} articles read, COMPLETE\".format(num_read))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345f6a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(vecs)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee96c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_r = umap.UMAP()\n",
    "\n",
    "## your code here\n",
    "\n",
    "\n",
    "## end your code here\n",
    "\n",
    "X_u.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd7aff7",
   "metadata": {},
   "source": [
    "### Visualize clustering using category labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18005320",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_u[:, 0], X_u[:, 1], c=y_c.astype(np.int32), cmap=plt.cm.viridis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9c1ded",
   "metadata": {},
   "source": [
    "### Visualize clustering using Louvain community predictions\n",
    "\n",
    "Complete the code below to visualize clusters using the `community_lv` predictions by the Louvain algorithm. It is similar to the code we showed above. remember that the `color (c)` parameter takes a numpy array of `dtype=np.int32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5b8bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here\n",
    "\n",
    "## end your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7a07f5",
   "metadata": {},
   "source": [
    "### Visualize clusters using Label Propagation Community predictions\n",
    "\n",
    "Now complete the code to visualize clusters using the `community_lp` predictions made by the Label Propagation algorithm. It is similar to the code you completed for the `community_lv` predictions from the Louvain algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b267e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here\n",
    "\n",
    "## end of your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a731bce",
   "metadata": {},
   "source": [
    "Clearly, of the three, the best clustering is produced by the Louvain algorithm, followed by Label Propagation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f503602a",
   "metadata": {},
   "source": [
    "## Recommending similar articles\n",
    "\n",
    "We seek to answer the question: given some node in a graph, what are some similar articles? This can be found using the Personalized PageRank, a variant of the [PageRank Algorithm](https://neo4j.com/docs/graph-data-science/current/algorithms/page-rank/).\n",
    "\n",
    "The difference between PageRank and Personalized PageRank is that the random surfer returns to a node or group of node instead of jumping to a random point in the web with some probability.\n",
    "\n",
    "Let us try to find similar articles to `0812.1124` the top article by degree centrality that we found earlier. Write a Cypher query to get 5 of its neighbors. You want to get the internal node ID of the neighbors, not the `doc_id`. You can use the `ID()` function to extract the internal node ID for a matched node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5d23cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.run(\n",
    "    ## your code here\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    ## end your code here\n",
    ")\n",
    "neighbors = list([r[\"doc_id\"] for r in result])\n",
    "neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141ca5e6",
   "metadata": {},
   "source": [
    "The `doc_id`s you identified plus the original node's `doc_id` will form our \"neighborhood\" for personalized PageRank computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8468c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors.append('0812.1124')\n",
    "neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d10f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.run(\n",
    "    \"\"\"\n",
    "    MATCH (a:Article) WHERE a.doc_id in [%s]\n",
    "    CALL gds.pageRank.stream('av-graph-gds', \n",
    "        {\n",
    "          maxIterations: 20,\n",
    "          dampingFactor: 0.85,\n",
    "          sourceNodes: [a]\n",
    "        })\n",
    "    YIELD nodeId, score\n",
    "    RETURN gds.util.asNode(nodeId).doc_id, gds.util.asNode(nodeId).title,\n",
    "           gds.util.asNode(nodeId).category, score\n",
    "    ORDER BY score DESC\n",
    "    LIMIT 30\n",
    "    \"\"\" % (\",\".join([\"'{:s}'\".format(nbr) for nbr in neighbors]))\n",
    ")\n",
    "show_result_as_dataframe(result, [\"doc_id\", \"title\", \"category\", \"score\"], filterset=set(neighbors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49805b43",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81f4739",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.run(\"\"\"CALL gds.graph.drop('av-graph-gds')\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cfe339",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph.run(\"\"\"CALL gds.graph.drop('av-graph-gds-1')\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bdafd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
